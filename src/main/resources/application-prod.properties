# 合并后文件的大小 不设置默认合并为一个文件
#spark.hadoop.mapreduce.input.fileinputformat.split.maxsize=52428800
# 集群的位置
# 使用spark合并的阈值
spark.merge.size=314572800
#fs.defaultFS.value=hdfs://mycluster:8020
#存放shell的路径
shell.path=/root/shell/exceMerge.sh
# jar报的位置
shell.spark.jar.location=/root/SparkMerge-1.0-SNAPSHOT-jar-with-dependencies.jar
# 主程序的名称
shell.spark.mainClass=com.guangda.SparkMerge
#命令
shell.spark.submit.command=./spark-submit --master yarn --deploy-mode cluster --class 
# 需要配置多个合并路径用逗号隔开,/megerlittlefile2/test01,/megerlittlefile2/test17
hdfs.file.intPutPath=/textoneG
# 对应顺序的输出路径用逗号隔开输出路径不能相同,/megerlittlefile2/test04,/megerlittlefile2/test05
hdfs.file.outPutPath=/megerlittlefile2/test04
# spark on yarn 的配置
# driver的内存
driver-memory=2g
# executor 的内存
executor-memory=2g
#executor 的核数
executor-cores=1
#linux的连接配置
linux.host=node4
linux.userName=root
linux.password=123456
linux.myPort=22
